{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Optimizers","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.datasets import mnist\nfrom keras.optimizers import Adam\n\n# Load the MNIST dataset\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# Normalize the input data\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0\n\n# Flatten the input images\nX_train = X_train.reshape((-1, 28*28))\nX_test = X_test.reshape((-1, 28*28))\n\n# Define the model\nmodel = Sequential([\n    Dense(512, activation='relu', input_shape=(28*28,)),\n    Dense(512, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\n# Compile the model with Adam optimizer\nadam_optimizer = Adam(learning_rate=0.001)  # Specify the learning rate\nmodel.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\n\nprint(\"Test Accuracy:\", test_accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:33:43.934048Z","iopub.execute_input":"2025-08-05T09:33:43.934344Z","iopub.status.idle":"2025-08-05T09:34:53.468966Z","shell.execute_reply.started":"2025-08-05T09:33:43.934320Z","shell.execute_reply":"2025-08-05T09:34:53.468122Z"}},"outputs":[{"name":"stderr","text":"2025-08-05 09:33:46.037208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754386426.282310      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754386426.360024      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n2025-08-05 09:34:02.544538: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8811 - loss: 0.4054 - val_accuracy: 0.9678 - val_loss: 0.0988\nEpoch 2/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9748 - loss: 0.0822 - val_accuracy: 0.9754 - val_loss: 0.0815\nEpoch 3/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0506 - val_accuracy: 0.9756 - val_loss: 0.0794\nEpoch 4/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9893 - loss: 0.0346 - val_accuracy: 0.9770 - val_loss: 0.0767\nEpoch 5/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0263 - val_accuracy: 0.9778 - val_loss: 0.0778\nEpoch 6/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0206 - val_accuracy: 0.9779 - val_loss: 0.0766\nEpoch 7/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0163 - val_accuracy: 0.9790 - val_loss: 0.0830\nEpoch 8/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.0153 - val_accuracy: 0.9795 - val_loss: 0.0873\nEpoch 9/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0142 - val_accuracy: 0.9825 - val_loss: 0.0683\nEpoch 10/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.9795 - val_loss: 0.0873\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.0972\nTest Accuracy: 0.9794999957084656\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.datasets import mnist\nfrom keras.optimizers import SGD, RMSprop, Adagrad\n\n# Load the MNIST dataset\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# Normalize the input data\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0\n\n# Flatten the input images\nX_train = X_train.reshape((-1, 28*28))\nX_test = X_test.reshape((-1, 28*28))\n\n# Define the model\nmodel = Sequential([\n    Dense(512, activation='relu', input_shape=(28*28,)),\n    Dense(512, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\n# Compile the model with different optimizers\noptimizers = [\n    SGD(learning_rate=0.01),  # Stochastic Gradient Descent\n    RMSprop(learning_rate=0.001),  # RMSprop\n    Adagrad(learning_rate=0.01)  # Adagrad\n]\n\nfor optimizer in optimizers:\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    # Train the model\n    history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n\n    # Evaluate the model on test data\n    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n    print(f\"Optimizer: {optimizer.__class__.__name__}, Test Accuracy: {test_accuracy}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T09:35:10.230017Z","iopub.execute_input":"2025-08-05T09:35:10.230984Z","iopub.status.idle":"2025-08-05T09:37:22.380516Z","shell.execute_reply.started":"2025-08-05T09:35:10.230955Z","shell.execute_reply":"2025-08-05T09:37:22.379643Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5842 - loss: 1.6431 - val_accuracy: 0.8772 - val_loss: 0.5274\nEpoch 2/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8749 - loss: 0.4941 - val_accuracy: 0.9005 - val_loss: 0.3716\nEpoch 3/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.3713 - val_accuracy: 0.9101 - val_loss: 0.3180\nEpoch 4/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9107 - loss: 0.3217 - val_accuracy: 0.9173 - val_loss: 0.2900\nEpoch 5/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9158 - loss: 0.2963 - val_accuracy: 0.9238 - val_loss: 0.2697\nEpoch 6/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9208 - loss: 0.2802 - val_accuracy: 0.9281 - val_loss: 0.2531\nEpoch 7/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9261 - loss: 0.2615 - val_accuracy: 0.9326 - val_loss: 0.2392\nEpoch 8/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.2394 - val_accuracy: 0.9367 - val_loss: 0.2287\nEpoch 9/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.2344 - val_accuracy: 0.9383 - val_loss: 0.2207\nEpoch 10/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.2195 - val_accuracy: 0.9399 - val_loss: 0.2096\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.2444\nOptimizer: SGD, Test Accuracy: 0.9398999810218811\nEpoch 1/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9202 - loss: 0.3013 - val_accuracy: 0.9597 - val_loss: 0.1335\nEpoch 2/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9725 - loss: 0.0861 - val_accuracy: 0.9757 - val_loss: 0.0815\nEpoch 3/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9831 - loss: 0.0526 - val_accuracy: 0.9781 - val_loss: 0.0724\nEpoch 4/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0337 - val_accuracy: 0.9812 - val_loss: 0.0643\nEpoch 5/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9922 - loss: 0.0251 - val_accuracy: 0.9791 - val_loss: 0.0746\nEpoch 6/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.9780 - val_loss: 0.0805\nEpoch 7/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0141 - val_accuracy: 0.9803 - val_loss: 0.0816\nEpoch 8/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.9799 - val_loss: 0.0821\nEpoch 9/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9845 - val_loss: 0.0749\nEpoch 10/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.9845 - val_loss: 0.0708\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0865\nOptimizer: RMSprop, Test Accuracy: 0.984499990940094\nEpoch 1/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9854 - val_loss: 0.0658\nEpoch 2/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9857 - val_loss: 0.0649\nEpoch 3/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 8.2149e-04 - val_accuracy: 0.9853 - val_loss: 0.0644\nEpoch 4/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 6.8018e-04 - val_accuracy: 0.9853 - val_loss: 0.0642\nEpoch 5/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.6907e-04 - val_accuracy: 0.9855 - val_loss: 0.0640\nEpoch 6/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.8092e-04 - val_accuracy: 0.9856 - val_loss: 0.0639\nEpoch 7/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7205e-04 - val_accuracy: 0.9856 - val_loss: 0.0639\nEpoch 8/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1889e-04 - val_accuracy: 0.9859 - val_loss: 0.0639\nEpoch 9/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.8268e-04 - val_accuracy: 0.9859 - val_loss: 0.0639\nEpoch 10/10\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.9066e-04 - val_accuracy: 0.9859 - val_loss: 0.0639\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0769\nOptimizer: Adagrad, Test Accuracy: 0.9858999848365784\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}