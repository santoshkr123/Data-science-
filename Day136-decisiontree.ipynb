{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Decision Tree & Decision Tree Classifier ","metadata":{}},{"cell_type":"markdown","source":"üå≥ Decision Tree\nA decision tree is a flowchart-like structure where each internal node represents a feature (or attribute), each branch represents a decision rule, and each leaf node represents an outcome.\n\nIt splits the dataset into smaller subsets based on feature values ‚Äî aiming to increase information gain (or reduce Gini impurity / entropy).","metadata":{}},{"cell_type":"markdown","source":"ü§ñ Decision Tree Classifier\nA supervised learning algorithm used for classification tasks\n\nAt each node, it chooses the best feature to split the data based on metrics like:\n\nGini Index\n\nEntropy / Information Gain\n\nIt continues splitting until a stopping condition is met (like max depth, min samples, or purity)\n\n","metadata":{}},{"cell_type":"markdown","source":"‚úÖ Advantages:\nEasy to understand and visualize\n\nNo need for feature scaling\n\nHandles both numerical and categorical data","metadata":{}},{"cell_type":"markdown","source":"‚ö†Ô∏è Disadvantages:\nCan overfit the training data\n\nSensitive to small changes in data","metadata":{}},{"cell_type":"markdown","source":"üß™ Example Use Cases:\nEmail Spam Detection\n\nLoan Default Prediction\n\nMedical Diagnosis (Yes/No outcomes)","metadata":{}},{"cell_type":"markdown","source":"üîç Key Terms:\nGini Index: Measures impurity; 0 is pure\n\nEntropy: Measures randomness/disorder in data\n\nInformation Gain: Reduction in entropy after a split","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}