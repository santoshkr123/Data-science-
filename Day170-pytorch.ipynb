{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"dfedfb45","cell_type":"code","source":"!pip install torch torchvision torchaudio","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torch in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (2.2.1)\n","Requirement already satisfied: torchvision in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (0.17.1)\n","Requirement already satisfied: torchaudio in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.10.0)\n","Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n","Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n","Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2022.11.0)\n","Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n","Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n","Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"]}],"execution_count":4},{"id":"ebc01561","cell_type":"code","source":"import torch","metadata":{},"outputs":[],"execution_count":5},{"id":"5ccbd7c3","cell_type":"markdown","source":"# Tensors\nAt its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number.","metadata":{}},{"id":"00cf6e9f","cell_type":"code","source":"# Number\nt1 = torch.tensor(4.)\nt1","metadata":{},"outputs":[{"data":{"text/plain":["tensor(4.)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":6},{"id":"ab8aed88","cell_type":"markdown","source":"4. is a shorthand for 4.0. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the dtype attribute of our tensor.","metadata":{}},{"id":"73ef798c","cell_type":"code","source":"t1.dtype","metadata":{},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"execution_count":7},{"id":"6ff4d4a3","cell_type":"markdown","source":"# Let's try creating more complex tensors.","metadata":{}},{"id":"b2f008d9","cell_type":"code","source":"# Vector\nt2 = torch.tensor([1., 2, 3, 4])\nt2","metadata":{},"outputs":[{"data":{"text/plain":["tensor([1., 2., 3., 4.])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"execution_count":8},{"id":"8f2f5a3c","cell_type":"code","source":"# Matrix\nt3 = torch.tensor([[5., 6], \n                   [7, 8], \n                   [9, 10]])\nt3","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 5.,  6.],\n","        [ 7.,  8.],\n","        [ 9., 10.]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"execution_count":9},{"id":"9154e134","cell_type":"code","source":"# 3-dimensional array\nt4 = torch.tensor([\n    [[11, 12, 13], \n     [13, 14, 15]], \n    [[15, 16, 17], \n     [17, 18, 19.]]])\nt4","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[11., 12., 13.],\n","         [13., 14., 15.]],\n","\n","        [[15., 16., 17.],\n","         [17., 18., 19.]]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"execution_count":10},{"id":"148d2e4f","cell_type":"markdown","source":"Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the .shape property of a tensor.","metadata":{}},{"id":"2d85d898","cell_type":"code","source":"print(t1)\nt1.shape","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(4.)\n"]},{"data":{"text/plain":["torch.Size([])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"execution_count":11},{"id":"3cf807d4","cell_type":"code","source":"print(t2)\nt2.shape","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 2., 3., 4.])\n"]},{"data":{"text/plain":["torch.Size([4])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"execution_count":12},{"id":"f923444e","cell_type":"code","source":"print(t3)\nt3.shape","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 5.,  6.],\n","        [ 7.,  8.],\n","        [ 9., 10.]])\n"]},{"data":{"text/plain":["torch.Size([3, 2])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"execution_count":13},{"id":"013f7673","cell_type":"code","source":"print(t4)\nt4.shape","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[11., 12., 13.],\n","         [13., 14., 15.]],\n","\n","        [[15., 16., 17.],\n","         [17., 18., 19.]]])\n"]},{"data":{"text/plain":["torch.Size([2, 2, 3])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"execution_count":14},{"id":"ff12966e","cell_type":"markdown","source":"# Note that it's not possible to create tensors with an improper shape.","metadata":{}},{"id":"9e3d953a","cell_type":"code","source":"# Matrix\nt5 = torch.tensor([[5., 6, 11], \n                   [7, 8], \n                   [9, 10]])\nt5","metadata":{},"outputs":[{"ename":"ValueError","evalue":"expected sequence of length 3 at dim 1 (got 2)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m t5 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m t5\n","\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"]}],"execution_count":15},{"id":"3baaad23","cell_type":"markdown","source":"# A ValueError is thrown because the lengths of the rows [5., 6, 11] and [7, 8] don't match.","metadata":{}},{"id":"3654051c","cell_type":"markdown","source":"# Tensor operations and gradients\nWe can combine tensors with the usual arithmetic operations. Let's look at an example:","metadata":{}},{"id":"2c05ca6d","cell_type":"code","source":"# Create tensors.\nx = torch.tensor(3.)\nw = torch.tensor(4., requires_grad=True)\nb = torch.tensor(5., requires_grad=True)\nx, w, b","metadata":{},"outputs":[],"execution_count":null},{"id":"ca897831","cell_type":"markdown","source":"We've created three tensors: x, w, and b, all numbers. w and b have an additional parameter requires_grad set to True. We'll see what it does in just a moment.\n\nLet's create a new tensor y by combining these tensors.","metadata":{}},{"id":"61da5fad","cell_type":"code","source":"# Arithmetic operations\ny = w * x + b\ny","metadata":{},"outputs":[],"execution_count":null},{"id":"80b07951","cell_type":"markdown","source":"As expected, y is a tensor with the value 3 * 4 + 5 = 17. What makes PyTorch unique is that we can automatically compute the derivative of y w.r.t. the tensors that have requires_grad set to True i.e. w and b. This feature of PyTorch is called autograd (automatic gradients).\n\nTo compute the derivatives, we can invoke the .backward method on our result y.\n\n","metadata":{}},{"id":"81c99b86","cell_type":"code","source":"# Compute derivatives\ny.backward()","metadata":{},"outputs":[],"execution_count":null},{"id":"082e5e0a","cell_type":"markdown","source":"The derivatives of y with respect to the input tensors are stored in the .grad property of the respective tensors.","metadata":{}},{"id":"767792ec","cell_type":"code","source":"# Display gradients\nprint('dy/dx:', x.grad)\nprint('dy/dw:', w.grad)\nprint('dy/db:', b.grad)","metadata":{},"outputs":[],"execution_count":null},{"id":"3fcff277","cell_type":"markdown","source":"As expected, dy/dw has the same value as x, i.e., 3, and dy/db has the value 1. Note that x.grad is None because x doesn't have requires_grad set to True.\n\nThe \"grad\" in w.grad is short for gradient, which is another term for derivative. The term gradient is primarily used while dealing with vectors and matrices.\n\n","metadata":{}},{"id":"9bb09955","cell_type":"markdown","source":"# Tensor functions\nApart from arithmetic operations, the torch module also contains many functions for creating and manipulating tensors. Let's look at some examples.","metadata":{}},{"id":"76f271b5","cell_type":"code","source":"# Create a tensor with a fixed value for every element\nt6 = torch.full((3, 2), 42)\nt6","metadata":{},"outputs":[],"execution_count":null},{"id":"d6616c19","cell_type":"code","source":"t3","metadata":{},"outputs":[],"execution_count":null},{"id":"d810ce77","cell_type":"code","source":"# Concatenate two tensors with compatible shapes\nt7 = torch.cat((t3, t6))\nt7","metadata":{},"outputs":[],"execution_count":null},{"id":"ff692cbb","cell_type":"code","source":"# Compute the sin of each element\nt8 = torch.sin(t7)\nt8","metadata":{},"outputs":[],"execution_count":null},{"id":"f11f6441","cell_type":"code","source":"# Change the shape of a tensor\nt9 = t8.reshape(3, 2, 2)\nt9","metadata":{},"outputs":[],"execution_count":null},{"id":"20c5ad33","cell_type":"markdown","source":"You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below.","metadata":{}},{"id":"fad83a7d","cell_type":"markdown","source":"# Interoperability with Numpy\n\n","metadata":{}},{"id":"8aded51c","cell_type":"code","source":"Numpy is a popular open-source library used for mathematical and scientific \ncomputing in Python. It enables efficient operations on \nlarge multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n\nPandas for file I/O and data analysis\nMatplotlib for plotting and visualization\nOpenCV for image and video processing\nInstead of reinventing the wheel, PyTorch interoperates well with Numpy\nto leverage its existing ecosystem of tools and libraries.","metadata":{},"outputs":[],"execution_count":null},{"id":"1fd18bd1","cell_type":"markdown","source":"Here's how we create an array in Numpy:","metadata":{}},{"id":"403f26ed","cell_type":"code","source":"import numpy as np\n\nx = np.array([[1, 2], [3, 4.]])\nx","metadata":{},"outputs":[{"data":{"text/plain":["array([[1., 2.],\n","       [3., 4.]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"execution_count":23},{"id":"81297483","cell_type":"markdown","source":"We can convert a Numpy array to a PyTorch tensor using torch.from_numpy.","metadata":{}},{"id":"9142d698","cell_type":"code","source":"# Convert the numpy array to a torch tensor.\ny = torch.from_numpy(x)\ny","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1., 2.],\n","        [3., 4.]], dtype=torch.float64)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"execution_count":24},{"id":"dd0ed9bc","cell_type":"markdown","source":"# Let's verify that the numpy array and torch tensor have similar data types.","metadata":{}},{"id":"0ff1e892","cell_type":"code","source":"x.dtype, y.dtype","metadata":{},"outputs":[{"data":{"text/plain":["(dtype('float64'), torch.float64)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"execution_count":26},{"id":"b3cc6ecf","cell_type":"markdown","source":"We can convert a PyTorch tensor to a Numpy array using the .numpy method of a tensor.","metadata":{}},{"id":"52928e94","cell_type":"code","source":"# Convert a torch tensor to a numpy array\nz = y.numpy()\nz","metadata":{},"outputs":[{"data":{"text/plain":["array([[1., 2.],\n","       [3., 4.]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"execution_count":27},{"id":"9949353d","cell_type":"markdown","source":"# The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n\nYou might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n\nAutograd: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\nGPU support: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.","metadata":{}},{"id":"da6427eb","cell_type":"markdown","source":"# Linear-regression from scrach using pytorch","metadata":{}},{"id":"a0fbab66","cell_type":"code","source":"import numpy as np\nimport torch","metadata":{},"outputs":[],"execution_count":16},{"id":"77601964","cell_type":"code","source":"#making training data \n# Input (temp, rainfall, humidity)\ninputs = np.array([[73, 67, 43], \n                   [91, 88, 64], \n                   [87, 134, 58], \n                   [102, 43, 37], \n                   [69, 96, 70]], dtype='float32')","metadata":{},"outputs":[],"execution_count":17},{"id":"415a2fa0","cell_type":"code","source":"# Targets (apples, oranges)\ntarget = np.array([[56, 70], \n                    [81, 101], \n                    [119, 133], \n                    [22, 37], \n                    [103, 119]], dtype='float32')","metadata":{},"outputs":[],"execution_count":18},{"id":"977b6035","cell_type":"code","source":"#Convert input and target to tensors\ninputs = torch.from_numpy(inputs)\ntarget = torch.from_numpy(target)\n\nprint(inputs,\"\\n\")\nprint(target)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]]) \n","\n","tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])\n"]}],"execution_count":19},{"id":"9b4bcae8","cell_type":"code","source":"# weights and biases\nw = torch.randn(2,3 , requires_grad=True)\nb = torch.randn(2, requires_grad=True)\n\nprint(w)\nprint(b)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.2885, -0.8025,  0.4200],\n","        [ 1.0883,  1.0860,  0.1029]], requires_grad=True)\n","tensor([1.9191, 0.6816], requires_grad=True)\n"]}],"execution_count":20},{"id":"da18c3b4","cell_type":"code","source":"#define the model\n\ndef model(x):\n    return x @ w.t() + b","metadata":{},"outputs":[],"execution_count":21},{"id":"d293537e","cell_type":"code","source":"# prediction\npreds = model(inputs)\nprint(preds)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-145.6381,  248.4880],\n","        [-186.7533,  325.7734],\n","        [-244.9442,  394.5558],\n","        [-139.2003,  240.0287],\n","        [-177.9548,  315.8690]], grad_fn=<AddBackward0>)\n"]}],"execution_count":42},{"id":"8520fbfe","cell_type":"code","source":"#actual\nprint(target)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])\n"]}],"execution_count":43},{"id":"4900c55d","cell_type":"code","source":"# loss function MSE\ndef MSE(actual, target):\n    diff = actual - target\n    return torch.sum(diff * diff) / diff.numel()","metadata":{},"outputs":[],"execution_count":44},{"id":"6f0adba7","cell_type":"code","source":"# error\nloss = MSE(target, preds)\nprint(loss)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(58049.6797, grad_fn=<DivBackward0>)\n"]}],"execution_count":45},{"id":"87055928","cell_type":"code","source":"# compute gradients\nloss.backward()","metadata":{},"outputs":[],"execution_count":46},{"id":"aed10d75","cell_type":"code","source":"print(w, \"\\n\")\nprint(w.grad)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.8547, -1.3262,  0.1009],\n","        [ 1.3051,  1.7187,  0.8429]], requires_grad=True) \n","\n","tensor([[-21315.3203, -23948.7676, -14509.3320],\n","        [ 18106.4492,  18883.3789,  11704.7217]])\n"]}],"execution_count":47},{"id":"19b3c1c4","cell_type":"code","source":"print(b, \"\\n\")\nprint(b.grad)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.2686, 1.8193], requires_grad=True) \n","\n","tensor([-255.0982,  212.9430])\n"]}],"execution_count":48},{"id":"deef46a5","cell_type":"code","source":"#reset grad\nw.grad.zero_()\nb.grad.zero_()\n\nprint(w.grad)\nprint(b.grad)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([0., 0.])\n"]}],"execution_count":49},{"id":"28438719","cell_type":"code","source":"# adjust params\n\npreds = model(inputs)\nprint(preds)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-145.6381,  248.4880],\n","        [-186.7533,  325.7734],\n","        [-244.9442,  394.5558],\n","        [-139.2003,  240.0287],\n","        [-177.9548,  315.8690]], grad_fn=<AddBackward0>)\n"]}],"execution_count":50},{"id":"fcd3260f","cell_type":"code","source":"# loss\nloss = MSE(target, preds)\nprint(loss)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(58049.6797, grad_fn=<DivBackward0>)\n"]}],"execution_count":51},{"id":"509809bb","cell_type":"code","source":"loss.backward()\n\nprint(w.grad, \"\\n\")\nprint(b.grad)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-21315.3203, -23948.7676, -14509.3320],\n","        [ 18106.4492,  18883.3789,  11704.7217]]) \n","\n","tensor([-255.0982,  212.9430])\n"]}],"execution_count":52},{"id":"5984d483","cell_type":"code","source":"  # adjust weight & reset grad\nwith torch.no_grad():\n    w -= w.grad * 1e-5\n    b -= b.grad * 1e-5\n    w.grad.zero_()\n    b.grad.zero_()","metadata":{},"outputs":[],"execution_count":53},{"id":"d220793f","cell_type":"code","source":"print(w)\nprint(b)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.6415, -1.0867,  0.2460],\n","        [ 1.1240,  1.5299,  0.7259]], requires_grad=True)\n","tensor([1.2712, 1.8172], requires_grad=True)\n"]}],"execution_count":54},{"id":"f24edc21","cell_type":"code","source":"# calculate again\npreds = model(inputs)\nloss = MSE(target, preds)\nprint(loss)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(39294.2891, grad_fn=<DivBackward0>)\n"]}],"execution_count":55},{"id":"6b7e31e0","cell_type":"code","source":"# Training for multiple epochs\nfor i in range(400):\n  preds = model(inputs)\n  loss = MSE(target, preds)\n  loss.backward()\n\n  with torch.no_grad():\n     w -= w.grad * 1e-5 # learning rate\n     b -= b.grad * 1e-5\n     w.grad.zero_()\n     b.grad.zero_()\n  print(f\"Epochs({i}/{100}) & Loss {loss}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epochs(0/100) & Loss 39294.2890625\n","Epochs(1/100) & Loss 26653.197265625\n","Epochs(2/100) & Loss 18132.46484375\n","Epochs(3/100) & Loss 12388.4150390625\n","Epochs(4/100) & Loss 8515.5517578125\n","Epochs(5/100) & Loss 5903.6845703125\n","Epochs(6/100) & Loss 4141.6083984375\n","Epochs(7/100) & Loss 2952.219482421875\n","Epochs(8/100) & Loss 2148.779052734375\n","Epochs(9/100) & Loss 1605.448974609375\n","Epochs(10/100) & Loss 1237.4271240234375\n","Epochs(11/100) & Loss 987.5665283203125\n","Epochs(12/100) & Loss 817.3563232421875\n","Epochs(13/100) & Loss 700.8442993164062\n","Epochs(14/100) & Loss 620.5413208007812\n","Epochs(15/100) & Loss 564.66162109375\n","Epochs(16/100) & Loss 525.262451171875\n","Epochs(17/100) & Loss 496.9911193847656\n","Epochs(18/100) & Loss 476.240234375\n","Epochs(19/100) & Loss 460.5782165527344\n","Epochs(20/100) & Loss 448.36688232421875\n","Epochs(21/100) & Loss 438.50146484375\n","Epochs(22/100) & Loss 430.23748779296875\n","Epochs(23/100) & Loss 423.0728454589844\n","Epochs(24/100) & Loss 416.6690368652344\n","Epochs(25/100) & Loss 410.79754638671875\n","Epochs(26/100) & Loss 405.3043518066406\n","Epochs(27/100) & Loss 400.085205078125\n","Epochs(28/100) & Loss 395.0697937011719\n","Epochs(29/100) & Loss 390.2103271484375\n","Epochs(30/100) & Loss 385.47454833984375\n","Epochs(31/100) & Loss 380.8402099609375\n","Epochs(32/100) & Loss 376.2924499511719\n","Epochs(33/100) & Loss 371.8206481933594\n","Epochs(34/100) & Loss 367.4177551269531\n","Epochs(35/100) & Loss 363.07855224609375\n","Epochs(36/100) & Loss 358.799560546875\n","Epochs(37/100) & Loss 354.57781982421875\n","Epochs(38/100) & Loss 350.4116516113281\n","Epochs(39/100) & Loss 346.29937744140625\n","Epochs(40/100) & Loss 342.23944091796875\n","Epochs(41/100) & Loss 338.23101806640625\n","Epochs(42/100) & Loss 334.27337646484375\n","Epochs(43/100) & Loss 330.3653564453125\n","Epochs(44/100) & Loss 326.5065002441406\n","Epochs(45/100) & Loss 322.6958312988281\n","Epochs(46/100) & Loss 318.93292236328125\n","Epochs(47/100) & Loss 315.217041015625\n","Epochs(48/100) & Loss 311.5473937988281\n","Epochs(49/100) & Loss 307.92376708984375\n","Epochs(50/100) & Loss 304.34527587890625\n","Epochs(51/100) & Loss 300.8113708496094\n","Epochs(52/100) & Loss 297.321533203125\n","Epochs(53/100) & Loss 293.87530517578125\n","Epochs(54/100) & Loss 290.47198486328125\n","Epochs(55/100) & Loss 287.11114501953125\n","Epochs(56/100) & Loss 283.7921142578125\n","Epochs(57/100) & Loss 280.51446533203125\n","Epochs(58/100) & Loss 277.2777099609375\n","Epochs(59/100) & Loss 274.08111572265625\n","Epochs(60/100) & Loss 270.92437744140625\n","Epochs(61/100) & Loss 267.80706787109375\n","Epochs(62/100) & Loss 264.72845458984375\n","Epochs(63/100) & Loss 261.6882629394531\n","Epochs(64/100) & Loss 258.6858215332031\n","Epochs(65/100) & Loss 255.720703125\n","Epochs(66/100) & Loss 252.79263305664062\n","Epochs(67/100) & Loss 249.9009246826172\n","Epochs(68/100) & Loss 247.04513549804688\n","Epochs(69/100) & Loss 244.2248992919922\n","Epochs(70/100) & Loss 241.439697265625\n","Epochs(71/100) & Loss 238.6891326904297\n","Epochs(72/100) & Loss 235.97280883789062\n","Epochs(73/100) & Loss 233.2902374267578\n","Epochs(74/100) & Loss 230.6409912109375\n","Epochs(75/100) & Loss 228.0245819091797\n","Epochs(76/100) & Loss 225.4407196044922\n","Epochs(77/100) & Loss 222.8889923095703\n","Epochs(78/100) & Loss 220.368896484375\n","Epochs(79/100) & Loss 217.880126953125\n","Epochs(80/100) & Loss 215.4221954345703\n","Epochs(81/100) & Loss 212.994873046875\n","Epochs(82/100) & Loss 210.59756469726562\n","Epochs(83/100) & Loss 208.22998046875\n","Epochs(84/100) & Loss 205.89181518554688\n","Epochs(85/100) & Loss 203.5826416015625\n","Epochs(86/100) & Loss 201.30209350585938\n","Epochs(87/100) & Loss 199.0498504638672\n","Epochs(88/100) & Loss 196.8254852294922\n","Epochs(89/100) & Loss 194.62863159179688\n","Epochs(90/100) & Loss 192.45907592773438\n","Epochs(91/100) & Loss 190.31643676757812\n","Epochs(92/100) & Loss 188.2002410888672\n","Epochs(93/100) & Loss 186.11026000976562\n","Epochs(94/100) & Loss 184.04612731933594\n","Epochs(95/100) & Loss 182.00762939453125\n","Epochs(96/100) & Loss 179.99423217773438\n","Epochs(97/100) & Loss 178.0057830810547\n","Epochs(98/100) & Loss 176.04196166992188\n","Epochs(99/100) & Loss 174.10240173339844\n","Epochs(100/100) & Loss 172.18685913085938\n","Epochs(101/100) & Loss 170.29495239257812\n","Epochs(102/100) & Loss 168.4263458251953\n","Epochs(103/100) & Loss 166.58096313476562\n","Epochs(104/100) & Loss 164.75827026367188\n","Epochs(105/100) & Loss 162.95816040039062\n","Epochs(106/100) & Loss 161.18020629882812\n","Epochs(107/100) & Loss 159.4241943359375\n","Epochs(108/100) & Loss 157.6898956298828\n","Epochs(109/100) & Loss 155.9769744873047\n","Epochs(110/100) & Loss 154.28524780273438\n","Epochs(111/100) & Loss 152.61419677734375\n","Epochs(112/100) & Loss 150.96388244628906\n","Epochs(113/100) & Loss 149.33387756347656\n","Epochs(114/100) & Loss 147.72396850585938\n","Epochs(115/100) & Loss 146.13389587402344\n","Epochs(116/100) & Loss 144.5633544921875\n","Epochs(117/100) & Loss 143.01214599609375\n","Epochs(118/100) & Loss 141.48001098632812\n","Epochs(119/100) & Loss 139.96682739257812\n","Epochs(120/100) & Loss 138.47213745117188\n","Epochs(121/100) & Loss 136.9959259033203\n","Epochs(122/100) & Loss 135.5377960205078\n","Epochs(123/100) & Loss 134.09762573242188\n","Epochs(124/100) & Loss 132.6751251220703\n","Epochs(125/100) & Loss 131.27011108398438\n","Epochs(126/100) & Loss 129.8822784423828\n","Epochs(127/100) & Loss 128.5115509033203\n","Epochs(128/100) & Loss 127.15766906738281\n","Epochs(129/100) & Loss 125.82032775878906\n","Epochs(130/100) & Loss 124.49942779541016\n","Epochs(131/100) & Loss 123.19468688964844\n","Epochs(132/100) & Loss 121.90596771240234\n","Epochs(133/100) & Loss 120.63304138183594\n","Epochs(134/100) & Loss 119.37564849853516\n","Epochs(135/100) & Loss 118.13374328613281\n","Epochs(136/100) & Loss 116.906982421875\n","Epochs(137/100) & Loss 115.6952133178711\n","Epochs(138/100) & Loss 114.4983139038086\n","Epochs(139/100) & Loss 113.31600189208984\n","Epochs(140/100) & Loss 112.1481704711914\n","Epochs(141/100) & Loss 110.99458312988281\n","Epochs(142/100) & Loss 109.85511779785156\n","Epochs(143/100) & Loss 108.72953796386719\n","Epochs(144/100) & Loss 107.61773681640625\n","Epochs(145/100) & Loss 106.51953125\n","Epochs(146/100) & Loss 105.4346694946289\n","Epochs(147/100) & Loss 104.36299896240234\n","Epochs(148/100) & Loss 103.30442810058594\n","Epochs(149/100) & Loss 102.2587661743164\n","Epochs(150/100) & Loss 101.22582244873047\n","Epochs(151/100) & Loss 100.2054443359375\n","Epochs(152/100) & Loss 99.19754028320312\n","Epochs(153/100) & Loss 98.20182800292969\n","Epochs(154/100) & Loss 97.2182388305664\n","Epochs(155/100) & Loss 96.24663543701172\n","Epochs(156/100) & Loss 95.28675842285156\n","Epochs(157/100) & Loss 94.3386459350586\n","Epochs(158/100) & Loss 93.40202331542969\n","Epochs(159/100) & Loss 92.47669219970703\n","Epochs(160/100) & Loss 91.56265258789062\n","Epochs(161/100) & Loss 90.65968322753906\n","Epochs(162/100) & Loss 89.76763153076172\n","Epochs(163/100) & Loss 88.88639068603516\n","Epochs(164/100) & Loss 88.0158462524414\n","Epochs(165/100) & Loss 87.1558609008789\n","Epochs(166/100) & Loss 86.30622863769531\n","Epochs(167/100) & Loss 85.46687316894531\n","Epochs(168/100) & Loss 84.63770294189453\n","Epochs(169/100) & Loss 83.81849670410156\n","Epochs(170/100) & Loss 83.00920104980469\n","Epochs(171/100) & Loss 82.20970153808594\n","Epochs(172/100) & Loss 81.4198226928711\n","Epochs(173/100) & Loss 80.63946533203125\n","Epochs(174/100) & Loss 79.86854553222656\n","Epochs(175/100) & Loss 79.10682678222656\n","Epochs(176/100) & Loss 78.35440826416016\n","Epochs(177/100) & Loss 77.6109619140625\n","Epochs(178/100) & Loss 76.87642669677734\n","Epochs(179/100) & Loss 76.15081787109375\n","Epochs(180/100) & Loss 75.43384552001953\n","Epochs(181/100) & Loss 74.72553253173828\n","Epochs(182/100) & Loss 74.02571868896484\n","Epochs(183/100) & Loss 73.33425903320312\n","Epochs(184/100) & Loss 72.65113067626953\n","Epochs(185/100) & Loss 71.9761734008789\n","Epochs(186/100) & Loss 71.30933380126953\n","Epochs(187/100) & Loss 70.65042877197266\n","Epochs(188/100) & Loss 69.99942779541016\n","Epochs(189/100) & Loss 69.35624694824219\n","Epochs(190/100) & Loss 68.72068786621094\n","Epochs(191/100) & Loss 68.09275817871094\n","Epochs(192/100) & Loss 67.47227478027344\n","Epochs(193/100) & Loss 66.85926818847656\n","Epochs(194/100) & Loss 66.25352478027344\n","Epochs(195/100) & Loss 65.655029296875\n","Epochs(196/100) & Loss 65.0635986328125\n","Epochs(197/100) & Loss 64.47929382324219\n","Epochs(198/100) & Loss 63.90187454223633\n","Epochs(199/100) & Loss 63.33134078979492\n","Epochs(200/100) & Loss 62.7675895690918\n","Epochs(201/100) & Loss 62.21052169799805\n","Epochs(202/100) & Loss 61.660057067871094\n","Epochs(203/100) & Loss 61.116119384765625\n","Epochs(204/100) & Loss 60.5786247253418\n","Epochs(205/100) & Loss 60.047508239746094\n","Epochs(206/100) & Loss 59.52263259887695\n","Epochs(207/100) & Loss 59.00404739379883\n","Epochs(208/100) & Loss 58.49153518676758\n","Epochs(209/100) & Loss 57.985107421875\n","Epochs(210/100) & Loss 57.484588623046875\n","Epochs(211/100) & Loss 56.990028381347656\n","Epochs(212/100) & Loss 56.50127029418945\n","Epochs(213/100) & Loss 56.01830291748047\n","Epochs(214/100) & Loss 55.54097366333008\n","Epochs(215/100) & Loss 55.069244384765625\n","Epochs(216/100) & Loss 54.603118896484375\n","Epochs(217/100) & Loss 54.14240646362305\n","Epochs(218/100) & Loss 53.687156677246094\n","Epochs(219/100) & Loss 53.23717498779297\n","Epochs(220/100) & Loss 52.792503356933594\n","Epochs(221/100) & Loss 52.3530387878418\n","Epochs(222/100) & Loss 51.91870880126953\n","Epochs(223/100) & Loss 51.48942184448242\n","Epochs(224/100) & Loss 51.065208435058594\n","Epochs(225/100) & Loss 50.645877838134766\n","Epochs(226/100) & Loss 50.231468200683594\n","Epochs(227/100) & Loss 49.821929931640625\n","Epochs(228/100) & Loss 49.4171142578125\n","Epochs(229/100) & Loss 49.016990661621094\n","Epochs(230/100) & Loss 48.62152862548828\n","Epochs(231/100) & Loss 48.230690002441406\n","Epochs(232/100) & Loss 47.84431076049805\n","Epochs(233/100) & Loss 47.462486267089844\n","Epochs(234/100) & Loss 47.08502960205078\n","Epochs(235/100) & Loss 46.71194839477539\n","Epochs(236/100) & Loss 46.34320068359375\n","Epochs(237/100) & Loss 45.97869110107422\n","Epochs(238/100) & Loss 45.618377685546875\n","Epochs(239/100) & Loss 45.26227569580078\n","Epochs(240/100) & Loss 44.910213470458984\n","Epochs(241/100) & Loss 44.56221389770508\n","Epochs(242/100) & Loss 44.21821212768555\n","Epochs(243/100) & Loss 43.87815856933594\n","Epochs(244/100) & Loss 43.542015075683594\n","Epochs(245/100) & Loss 43.20974349975586\n","Epochs(246/100) & Loss 42.88121795654297\n","Epochs(247/100) & Loss 42.556495666503906\n","Epochs(248/100) & Loss 42.23545837402344\n","Epochs(249/100) & Loss 41.91809844970703\n","Epochs(250/100) & Loss 41.60436248779297\n","Epochs(251/100) & Loss 41.29423141479492\n","Epochs(252/100) & Loss 40.98757553100586\n","Epochs(253/100) & Loss 40.68440628051758\n","Epochs(254/100) & Loss 40.384700775146484\n","Epochs(255/100) & Loss 40.0883674621582\n","Epochs(256/100) & Loss 39.795448303222656\n","Epochs(257/100) & Loss 39.505775451660156\n","Epochs(258/100) & Loss 39.21942901611328\n","Epochs(259/100) & Loss 38.93629837036133\n","Epochs(260/100) & Loss 38.65633773803711\n","Epochs(261/100) & Loss 38.379547119140625\n","Epochs(262/100) & Loss 38.10588455200195\n","Epochs(263/100) & Loss 37.83530044555664\n","Epochs(264/100) & Loss 37.56774139404297\n","Epochs(265/100) & Loss 37.30318069458008\n","Epochs(266/100) & Loss 37.04155731201172\n","Epochs(267/100) & Loss 36.78287887573242\n","Epochs(268/100) & Loss 36.527076721191406\n","Epochs(269/100) & Loss 36.274200439453125\n","Epochs(270/100) & Loss 36.0240592956543\n","Epochs(271/100) & Loss 35.77676010131836\n","Epochs(272/100) & Loss 35.53215789794922\n","Epochs(273/100) & Loss 35.29033279418945\n","Epochs(274/100) & Loss 35.05116271972656\n","Epochs(275/100) & Loss 34.81462478637695\n","Epochs(276/100) & Loss 34.58069610595703\n","Epochs(277/100) & Loss 34.34934997558594\n","Epochs(278/100) & Loss 34.12061309814453\n","Epochs(279/100) & Loss 33.89433288574219\n","Epochs(280/100) & Loss 33.67058563232422\n","Epochs(281/100) & Loss 33.44927215576172\n","Epochs(282/100) & Loss 33.23041534423828\n","Epochs(283/100) & Loss 33.013885498046875\n","Epochs(284/100) & Loss 32.79977798461914\n","Epochs(285/100) & Loss 32.5880012512207\n","Epochs(286/100) & Loss 32.37851333618164\n","Epochs(287/100) & Loss 32.171348571777344\n","Epochs(288/100) & Loss 31.966434478759766\n","Epochs(289/100) & Loss 31.76371192932129\n","Epochs(290/100) & Loss 31.563196182250977\n","Epochs(291/100) & Loss 31.364871978759766\n","Epochs(292/100) & Loss 31.16868019104004\n","Epochs(293/100) & Loss 30.974605560302734\n","Epochs(294/100) & Loss 30.782638549804688\n","Epochs(295/100) & Loss 30.592700958251953\n","Epochs(296/100) & Loss 30.40484619140625\n","Epochs(297/100) & Loss 30.21897315979004\n","Epochs(298/100) & Loss 30.035146713256836\n","Epochs(299/100) & Loss 29.853225708007812\n","Epochs(300/100) & Loss 29.673269271850586\n","Epochs(301/100) & Loss 29.4952392578125\n","Epochs(302/100) & Loss 29.319072723388672\n","Epochs(303/100) & Loss 29.14480972290039\n","Epochs(304/100) & Loss 28.972423553466797\n","Epochs(305/100) & Loss 28.801809310913086\n","Epochs(306/100) & Loss 28.633014678955078\n","Epochs(307/100) & Loss 28.46600341796875\n","Epochs(308/100) & Loss 28.30072593688965\n","Epochs(309/100) & Loss 28.137222290039062\n","Epochs(310/100) & Loss 27.97539710998535\n","Epochs(311/100) & Loss 27.815338134765625\n","Epochs(312/100) & Loss 27.656902313232422\n","Epochs(313/100) & Loss 27.500112533569336\n","Epochs(314/100) & Loss 27.344980239868164\n","Epochs(315/100) & Loss 27.19146728515625\n","Epochs(316/100) & Loss 27.039539337158203\n","Epochs(317/100) & Loss 26.889169692993164\n","Epochs(318/100) & Loss 26.740367889404297\n","Epochs(319/100) & Loss 26.593149185180664\n","Epochs(320/100) & Loss 26.4473934173584\n","Epochs(321/100) & Loss 26.30313491821289\n","Epochs(322/100) & Loss 26.160375595092773\n","Epochs(323/100) & Loss 26.019073486328125\n","Epochs(324/100) & Loss 25.879220962524414\n","Epochs(325/100) & Loss 25.74077796936035\n","Epochs(326/100) & Loss 25.603775024414062\n","Epochs(327/100) & Loss 25.468175888061523\n","Epochs(328/100) & Loss 25.333913803100586\n","Epochs(329/100) & Loss 25.2010555267334\n","Epochs(330/100) & Loss 25.069480895996094\n","Epochs(331/100) & Loss 24.93926429748535\n","Epochs(332/100) & Loss 24.810354232788086\n","Epochs(333/100) & Loss 24.682754516601562\n","Epochs(334/100) & Loss 24.55641746520996\n","Epochs(335/100) & Loss 24.431346893310547\n","Epochs(336/100) & Loss 24.30752182006836\n","Epochs(337/100) & Loss 24.184925079345703\n","Epochs(338/100) & Loss 24.063554763793945\n","Epochs(339/100) & Loss 23.943389892578125\n","Epochs(340/100) & Loss 23.824399948120117\n","Epochs(341/100) & Loss 23.706588745117188\n","Epochs(342/100) & Loss 23.58993148803711\n","Epochs(343/100) & Loss 23.474441528320312\n","Epochs(344/100) & Loss 23.360057830810547\n","Epochs(345/100) & Loss 23.24679946899414\n","Epochs(346/100) & Loss 23.13465118408203\n","Epochs(347/100) & Loss 23.023603439331055\n","Epochs(348/100) & Loss 22.91363525390625\n","Epochs(349/100) & Loss 22.80471420288086\n","Epochs(350/100) & Loss 22.69684600830078\n","Epochs(351/100) & Loss 22.590044021606445\n","Epochs(352/100) & Loss 22.4842472076416\n","Epochs(353/100) & Loss 22.37944984436035\n","Epochs(354/100) & Loss 22.275686264038086\n","Epochs(355/100) & Loss 22.172924041748047\n","Epochs(356/100) & Loss 22.07107925415039\n","Epochs(357/100) & Loss 21.97024917602539\n","Epochs(358/100) & Loss 21.870372772216797\n","Epochs(359/100) & Loss 21.771421432495117\n","Epochs(360/100) & Loss 21.673412322998047\n","Epochs(361/100) & Loss 21.576313018798828\n","Epochs(362/100) & Loss 21.480154037475586\n","Epochs(363/100) & Loss 21.384872436523438\n","Epochs(364/100) & Loss 21.29048728942871\n","Epochs(365/100) & Loss 21.196992874145508\n","Epochs(366/100) & Loss 21.10433006286621\n","Epochs(367/100) & Loss 21.012537002563477\n","Epochs(368/100) & Loss 20.92160987854004\n","Epochs(369/100) & Loss 20.83149528503418\n","Epochs(370/100) & Loss 20.74222183227539\n","Epochs(371/100) & Loss 20.653785705566406\n","Epochs(372/100) & Loss 20.566120147705078\n","Epochs(373/100) & Loss 20.479272842407227\n","Epochs(374/100) & Loss 20.393184661865234\n","Epochs(375/100) & Loss 20.30791473388672\n","Epochs(376/100) & Loss 20.223400115966797\n","Epochs(377/100) & Loss 20.139652252197266\n","Epochs(378/100) & Loss 20.056629180908203\n","Epochs(379/100) & Loss 19.974355697631836\n","Epochs(380/100) & Loss 19.89282989501953\n","Epochs(381/100) & Loss 19.812030792236328\n","Epochs(382/100) & Loss 19.73193359375\n","Epochs(383/100) & Loss 19.652568817138672\n","Epochs(384/100) & Loss 19.5738582611084\n","Epochs(385/100) & Loss 19.495866775512695\n","Epochs(386/100) & Loss 19.4185848236084\n","Epochs(387/100) & Loss 19.3419246673584\n","Epochs(388/100) & Loss 19.265975952148438\n","Epochs(389/100) & Loss 19.190675735473633\n","Epochs(390/100) & Loss 19.116003036499023\n","Epochs(391/100) & Loss 19.0419921875\n","Epochs(392/100) & Loss 18.968595504760742\n","Epochs(393/100) & Loss 18.895862579345703\n","Epochs(394/100) & Loss 18.823741912841797\n","Epochs(395/100) & Loss 18.752208709716797\n","Epochs(396/100) & Loss 18.681293487548828\n","Epochs(397/100) & Loss 18.610986709594727\n","Epochs(398/100) & Loss 18.541255950927734\n","Epochs(399/100) & Loss 18.47213363647461\n"]}],"execution_count":56},{"id":"a7d09c8a","cell_type":"code","source":"preds = model(inputs)\nloss = MSE(target, preds)\nprint(loss)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(18.4036, grad_fn=<DivBackward0>)\n"]}],"execution_count":57},{"id":"2c4b4af2","cell_type":"code","source":"from math import sqrt\nsqrt(loss)","metadata":{},"outputs":[{"data":{"text/plain":["4.289942249896412"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"execution_count":58},{"id":"e87b9214","cell_type":"code","source":"preds","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 57.8801,  71.4046],\n","        [ 84.2536,  97.3319],\n","        [112.8927, 138.7951],\n","        [ 24.1537,  41.2168],\n","        [103.9399, 111.2345]], grad_fn=<AddBackward0>)"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"execution_count":59},{"id":"5605c3d9","cell_type":"code","source":"target","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"execution_count":60},{"id":"dc280f27","cell_type":"markdown","source":"# You can see they are almost close earch other","metadata":{}},{"id":"23116953","cell_type":"markdown","source":"# Neural Network using Pytorch","metadata":{}},{"id":"eb760c7d","cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor, Lambda, Compose\nimport matplotlib.pyplot as plt","metadata":{},"outputs":[],"execution_count":65},{"id":"505b9dd5","cell_type":"code","source":"# Download training data from open datasets.\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:17<00:00, 1536936.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00<00:00, 207979.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3444650.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00<00:00, 2592421.30it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":67},{"id":"b9668788","cell_type":"code","source":"type(training_data)","metadata":{},"outputs":[{"data":{"text/plain":["torchvision.datasets.mnist.FashionMNIST"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"execution_count":68},{"id":"ab274495","cell_type":"code","source":"batch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(\"Shape of X [N, C, H, W]: \", X.shape)\n    print(\"Shape of y: \", y.shape, y.dtype)\n    # print(X)\n    # print(y)\n    break","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n","Shape of y:  torch.Size([64]) torch.int64\n"]}],"execution_count":69},{"id":"026d8708","cell_type":"code","source":"X.shape prints the shape of the input data tensor X.\nIn this case, it prints the shape in the format [N, C, H, W], \nwhere N is the batch size, C is the number of channels \n(e.g., for RGB images, C would be 3), H is the height,\nand W is the width of each sample in the batch.","metadata":{},"outputs":[],"execution_count":null},{"id":"6d5aebde","cell_type":"code","source":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]}],"execution_count":70},{"id":"8688805c","cell_type":"code","source":"# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"execution_count":71},{"id":"812a290f","cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)","metadata":{},"outputs":[],"execution_count":72},{"id":"42dba717","cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{},"outputs":[],"execution_count":73},{"id":"d276eb54","cell_type":"code","source":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{},"outputs":[],"execution_count":74},{"id":"bdfcbf51","cell_type":"code","source":"epochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 2.295748  [    0/60000]\n","loss: 2.291415  [ 6400/60000]\n","loss: 2.273428  [12800/60000]\n","loss: 2.275123  [19200/60000]\n","loss: 2.246910  [25600/60000]\n","loss: 2.224137  [32000/60000]\n","loss: 2.241773  [38400/60000]\n","loss: 2.207633  [44800/60000]\n","loss: 2.204364  [51200/60000]\n","loss: 2.174191  [57600/60000]\n","Test Error: \n"," Accuracy: 45.8%, Avg loss: 2.168380 \n","\n","Epoch 2\n","-------------------------------\n","loss: 2.176975  [    0/60000]\n","loss: 2.172533  [ 6400/60000]\n","loss: 2.112639  [12800/60000]\n","loss: 2.132830  [19200/60000]\n","loss: 2.081084  [25600/60000]\n","loss: 2.021886  [32000/60000]\n","loss: 2.067733  [38400/60000]\n","loss: 1.988711  [44800/60000]\n","loss: 1.996453  [51200/60000]\n","loss: 1.928489  [57600/60000]\n","Test Error: \n"," Accuracy: 55.0%, Avg loss: 1.918153 \n","\n","Epoch 3\n","-------------------------------\n","loss: 1.950550  [    0/60000]\n","loss: 1.927153  [ 6400/60000]\n","loss: 1.800188  [12800/60000]\n","loss: 1.846008  [19200/60000]\n","loss: 1.740488  [25600/60000]\n","loss: 1.679178  [32000/60000]\n","loss: 1.729029  [38400/60000]\n","loss: 1.615752  [44800/60000]\n","loss: 1.642105  [51200/60000]\n","loss: 1.545944  [57600/60000]\n","Test Error: \n"," Accuracy: 59.0%, Avg loss: 1.547810 \n","\n","Epoch 4\n","-------------------------------\n","loss: 1.609800  [    0/60000]\n","loss: 1.583614  [ 6400/60000]\n","loss: 1.419811  [12800/60000]\n","loss: 1.498951  [19200/60000]\n","loss: 1.381377  [25600/60000]\n","loss: 1.362645  [32000/60000]\n","loss: 1.405608  [38400/60000]\n","loss: 1.312612  [44800/60000]\n","loss: 1.347502  [51200/60000]\n","loss: 1.255945  [57600/60000]\n","Test Error: \n"," Accuracy: 62.7%, Avg loss: 1.272441 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.343744  [    0/60000]\n","loss: 1.337273  [ 6400/60000]\n","loss: 1.160208  [12800/60000]\n","loss: 1.270177  [19200/60000]\n","loss: 1.147516  [25600/60000]\n","loss: 1.159042  [32000/60000]\n","loss: 1.205224  [38400/60000]\n","loss: 1.126139  [44800/60000]\n","loss: 1.164041  [51200/60000]\n","loss: 1.087526  [57600/60000]\n","Test Error: \n"," Accuracy: 64.4%, Avg loss: 1.102038 \n","\n","Done!\n"]}],"execution_count":75},{"id":"ddb65007","cell_type":"code","source":"#save model\ntorch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved PyTorch Model State to model.pth\n"]}],"execution_count":76},{"id":"792487d9","cell_type":"code","source":"#load model\nmodel = NeuralNetwork()\nmodel.load_state_dict(torch.load(\"model.pth\"))","metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"execution_count":77},{"id":"863a7ade","cell_type":"code","source":"## Prediction\n\nclasses = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}],"execution_count":79},{"id":"5350e56a","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"59e4261c","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"26be0d1e","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"4c169ca4","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"f9224923","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"id":"8ff9f020","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}