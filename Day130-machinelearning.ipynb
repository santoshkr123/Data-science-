{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ğ—–ğ—¼ğ—»ğ—³ğ˜‚ğ˜€ğ—¶ğ—¼ğ—» ğ— ğ—®ğ˜ğ—¿ğ—¶ğ˜… & ğ—˜ğ˜ƒğ—®ğ—¹ğ˜‚ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ— ğ—²ğ˜ğ—¿ğ—¶ğ—°ğ˜€","metadata":{}},{"cell_type":"markdown","source":"ğŸ§© ğ—–ğ—¼ğ—»ğ—³ğ˜‚ğ˜€ğ—¶ğ—¼ğ—» ğ— ğ—®ğ˜ğ—¿ğ—¶ğ˜…\nA ğ—°ğ—¼ğ—»ğ—³ğ˜‚ğ˜€ğ—¶ğ—¼ğ—» ğ—ºğ—®ğ˜ğ—¿ğ—¶ğ˜… is a summary table used to evaluate the performance of a classification model. It shows the number of:\nâœ… ğ—§ğ—¿ğ˜‚ğ—² ğ—£ğ—¼ğ˜€ğ—¶ğ˜ğ—¶ğ˜ƒğ—²ğ˜€ (ğ—§ğ—£): Correctly predicted positive cases\nâŒ ğ—™ğ—®ğ—¹ğ˜€ğ—² ğ—£ğ—¼ğ˜€ğ—¶ğ˜ğ—¶ğ˜ƒğ—²ğ˜€ (ğ—™ğ—£): Incorrectly predicted as positive\nâ ğ—§ğ—¿ğ˜‚ğ—² ğ—¡ğ—²ğ—´ğ—®ğ˜ğ—¶ğ˜ƒğ—²ğ˜€ (ğ—§ğ—¡): Correctly predicted negative cases\nâš ï¸ ğ—™ğ—®ğ—¹ğ˜€ğ—² ğ—¡ğ—²ğ—´ğ—®ğ˜ğ—¶ğ˜ƒğ—²ğ˜€ (ğ—™ğ—¡): Incorrectly predicted as negative","metadata":{}},{"cell_type":"markdown","source":"âœ… ğ—”ğ—°ğ—°ğ˜‚ğ—¿ğ—®ğ—°ğ˜†\nThe ratio of correctly predicted observations (TP + TN) to the total observations.\nAccuracy=TP+TN / TP+FP+FN+TN\nâœ… Great when classes are balanced\nâš ï¸ Misleading if the data is imbalanced.","metadata":{}},{"cell_type":"markdown","source":"ğŸ¯ ğ—£ğ—¿ğ—²ğ—°ğ—¶ğ˜€ğ—¶ğ—¼ğ—»\nOut of all predicted positives, how many are actually positive?\nPrecision = TP /TP +FP\nâœ… Useful when ğ—³ğ—®ğ—¹ğ˜€ğ—² ğ—½ğ—¼ğ˜€ğ—¶ğ˜ğ—¶ğ˜ƒğ—²ğ˜€ ğ—®ğ—¿ğ—² ğ—°ğ—¼ğ˜€ğ˜ğ—¹ğ˜† (e.g., spam detection).","metadata":{}},{"cell_type":"markdown","source":"ğŸ“ˆ ğ—¥ğ—²ğ—°ğ—®ğ—¹ğ—¹ (ğ—¦ğ—²ğ—»ğ˜€ğ—¶ğ˜ğ—¶ğ˜ƒğ—¶ğ˜ğ˜† ğ—¼ğ—¿ ğ—§ğ—£ğ—¥)\nOut of all actual positives, how many were correctly predicted?\nRecall = TP /TP+FN\n\nğŸ§  ğ—™ğŸ­-ğ—¦ğ—°ğ—¼ğ—¿ğ—²\nThe harmonic mean of Precision and Recall.\nF 1=2â‹… Precision*Recall /Precision +Recall","metadata":{}},{"cell_type":"markdown","source":"ğ—œğ—³ ğ—™ğ—£ ğ—¶ğ˜€ ğ—ºğ—¼ğ—¿ğ—² ğ—¶ğ—ºğ—½ğ—¼ğ—¿ğ˜ğ—®ğ—»ğ˜ ğ˜ğ—µğ—®ğ—» ğ—™ğ—¡ :\nB=\nF 0.5 Score = 1.25[P*R] / P+R\n\nIf FN is more important than PF :\nB=2\nF 2 Score = 5[P*R] / P+R","metadata":{}},{"cell_type":"markdown","source":"ğŸ’¡ Summary:\nChoose metrics based on the problem â€” not just accuracy. Understand what matters: precision or recall, and use F1 or F-beta accordingly.","metadata":{}}]}